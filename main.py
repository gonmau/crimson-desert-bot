import requests
from bs4 import BeautifulSoup
import os

def get_news(url, count=3):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.content, 'xml')
        items = soup.find_all('item')[:count]
        
        results = []
        for item in items:
            # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
            title = item.title.text
            link = item.link.text
            results.append(f"â€¢ **{title}**\n  <{link}>")
        return results
    except Exception as e:
        print(f"Error fetching news: {e}")
        return []

def main():
    # 1. í•œêµ­ ì†Œì‹ (ë¶‰ì€ì‚¬ë§‰)
    kr_url = "https://news.google.com/rss/search?q=ë¶‰ì€ì‚¬ë§‰&hl=ko&gl=KR&ceid=KR:ko"
    kr_news = get_news(kr_url)

    # 2. í•´ì™¸ ì†Œì‹ (Crimson Desert) - ë¯¸êµ­ êµ¬ê¸€ ë‰´ìŠ¤ ê¸°ì¤€
    en_url = 'https://news.google.com/rss/search?q="Crimson+Desert"&hl=en-US&gl=US&ceid=US:en'
    en_news = get_news(en_url)

    # ë©”ì‹œì§€ ì¡°ë¦½
    message_parts = ["ğŸ® **ì˜¤ëŠ˜ì˜ ë¶‰ì€ì‚¬ë§‰(Crimson Desert) í†µí•© ì†Œì‹** ğŸ®\n"]
    
    if kr_news:
        message_parts.append("ğŸ‡°ğŸ‡· **êµ­ë‚´ ìµœì‹  ë‰´ìŠ¤**")
        message_parts.extend(kr_news)
    
    message_parts.append("\n-------------------\n")
    
    if en_news:
        message_parts.append("ğŸŒ **í•´ì™¸ ìµœì‹  ë‰´ìŠ¤ (Global)**")
        message_parts.extend(en_news)

    full_content = "\n".join(message_parts)

    # ë””ìŠ¤í¬ë“œë¡œ ì „ì†¡
    webhook_url = os.environ.get('DISCORD_WEBHOOK_URL')
    if webhook_url:
        payload = {"content": full_content}
        requests.post(webhook_url, json=payload)
        print("ì „ì†¡ ì™„ë£Œ!")
    else:
        print("Webhook URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
